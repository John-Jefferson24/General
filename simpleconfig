## MODEL PROXY CONFIGURATION ##

# Load only necessary modules
LoadModule security2_module modules/mod_security2.so
LoadModule proxy_module modules/mod_proxy.so
LoadModule proxy_http_module modules/mod_proxy_http.so
LoadModule rewrite_module modules/mod_rewrite.so
LoadModule headers_module modules/mod_headers.so

# Essential logging
LogLevel warn
ErrorLog /var/log/httpd/proxy_error.log
CustomLog /var/log/httpd/proxy_access.log combined

<VirtualHost *:80>
    ProxyPreserveHost On
    
    # ModSecurity for JSON parsing and model extraction (read-only, no modification)
    <IfModule mod_security2.c>
        SecRuleEngine On
        SecRequestBodyAccess On
        SecResponseBodyAccess Off
        
        # Increased request body limits for large model inputs (200MB)
        SecRequestBodyLimit 209715200
        SecRequestBodyLimitAction ProcessPartial
        
        # Enable JSON processing
        SecRule REQUEST_HEADERS:Content-Type "application/json" "id:1000,pass,ctl:requestBodyProcessor=JSON"
        
        # Extract specific model names and set routing variables
        SecRule REQUEST_BODY:model "@streq gpt-model-1" "id:2001,phase:2,pass,setvar:tx.model_route=model1,setenv:MODEL_ROUTE=model1"
        SecRule REQUEST_BODY:model "@streq gpt-model-2" "id:2002,phase:2,pass,setvar:tx.model_route=model2,setenv:MODEL_ROUTE=model2"
        SecRule REQUEST_BODY:model "@streq gpt-model-3" "id:2003,phase:2,pass,setvar:tx.model_route=model3,setenv:MODEL_ROUTE=model3"
        SecRule REQUEST_BODY:model "@streq gpt-model-4" "id:2004,phase:2,pass,setvar:tx.model_route=model4,setenv:MODEL_ROUTE=model4"
        SecRule REQUEST_BODY:model "@streq gpt-model-5" "id:2005,phase:2,pass,setvar:tx.model_route=model5,setenv:MODEL_ROUTE=model5"
        
        # Debug logging for ModSecurity
        SecDebugLogLevel 3
        SecDebugLog /var/log/httpd/modsec_debug.log
    </IfModule>
    
    # URL rewriting for request routing
    RewriteEngine On
    RewriteLogLevel 3
    
    # Debug logging
    RewriteLog /var/log/httpd/rewrite.log
    
    # Model routing based on the model_route variable
    RewriteCond %{ENV:MODEL_ROUTE} ^model1$
    RewriteRule ^/$ /model1 [PT]
    
    RewriteCond %{ENV:MODEL_ROUTE} ^model2$
    RewriteRule ^/$ /model2 [PT]
    
    RewriteCond %{ENV:MODEL_ROUTE} ^model3$
    RewriteRule ^/$ /model3 [PT]
    
    RewriteCond %{ENV:MODEL_ROUTE} ^model4$
    RewriteRule ^/$ /model4 [PT]
    
    RewriteCond %{ENV:MODEL_ROUTE} ^model5$
    RewriteRule ^/$ /model5 [PT]
    
    # Now set up the ProxyPass directives for each model route
    ProxyPass /model1 http://triton1.internal/v1/chat/completions
    ProxyPass /model2 http://triton2.internal/v1/chat/completions
    ProxyPass /model3 http://triton3.internal/v1/chat/completions
    ProxyPass /model4 http://triton4.internal/v1/chat/completions
    ProxyPass /model5 http://triton5.internal/v1/chat/completions
    
    # Default fallback for root - use model1
    RewriteRule ^/$ /model1 [PT]
    
    # Forward client IP 
    RequestHeader set X-Forwarded-For %{REMOTE_ADDR}s
    
    # Add debug header
    RequestHeader set X-Model-Route "%{MODEL_ROUTE}e" env=MODEL_ROUTE
    
    # Streaming compatibility headers for OpenAI, LangChain, and other frameworks
    Header always set Access-Control-Allow-Origin "*"
    Header always set Access-Control-Allow-Headers "Content-Type, Authorization"
    Header always set Access-Control-Allow-Methods "POST, GET, OPTIONS"
    Header always set Cache-Control "no-store"
    
    # Proxy options to properly handle streaming responses
    ProxyRequests Off
</VirtualHost>
